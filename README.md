# Pipeline de DonnÃ©es Temps RÃ©el â€“ Redpanda + Spark Structured Streaming

### Proof of Concept â€” Pipeline de streaming temps rÃ©el avec Python, Redpanda et Apache Spark

##  PrÃ©sentation

Ce projet illustre la mise en place dâ€™un **pipeline de traitement de donnÃ©es en temps rÃ©el**, entiÃ¨rement conteneurisÃ© avec Docker.
Il combine plusieurs briques technologiques modernes :

* **Redpanda** â†’ Broker de messages Kafka-compatible, lÃ©ger et performant
* **Producteur Python** â†’ GÃ©nÃ©ration de tickets clients simulÃ©s (via `faker`)
* **Apache Spark Structured Streaming** â†’ Lecture continue et agrÃ©gation en temps rÃ©el
* **Redpanda Console** â†’ Interface web de visualisation des topics et des messages

Lâ€™objectif est de dÃ©montrer comment **produire**, **consommer** et **traiter** des flux de donnÃ©es en temps rÃ©el de bout en bout, dans une architecture reproductible et simple Ã  dÃ©ployer.

---

##  Description du Pipeline

1. **`tickets-generator`**
   GÃ©nÃ¨re en continu des tickets clients factices envoyÃ©s au topic `client_tickets` :

   ```json
   {
     "ticket_id": 1452,
     "client_id": 9743,
     "created_at": "2025-10-14T09:25:43",
     "request": "Je ne peux plus accÃ©der Ã  mon compte.",
     "type": "support",
     "priority": "haute"
   }
   ```

2. **`spark-stream`**
   Lit les messages du topic et calcule en temps rÃ©el :

   * le nombre de tickets par `type` et `priority`,
   * ignore les messages malformÃ©s sans bloquer le flux,
   * exporte les agrÃ©gations :

     * dans la **console Spark**,
     * dans un **fichier JSON** mis Ã  jour en continu.

3. **`redpanda-console`**
   Permet de visualiser les topics et messages Ã  lâ€™adresse :
   ðŸ‘‰ [http://localhost:8080](http://localhost:8080)

---

## Diagramme des flux de donnÃ©es
```mermaid
flowchart TD
    A[Redpanda<br/>Topic: client_tickets]
    B[PySpark Streaming<br/>lecture Kafka â†’ parsing JSON]
    C[GroupBy : type, priority<br/>count]
    D1[Sortie console]
    D2[Export JSON]
    E[Checkpoint]

    A --> B --> C
    C --> D1
    C --> D2
    C --> E
```

--- 

## DÃ©marrage avec Docker

### 1. Lancer lâ€™environnement

```bash
docker compose up -d
```

### 2. VÃ©rifier les logs

```bash
docker logs -f tickets-generator
docker logs -f spark-stream
```

### 3. Ouvrir la console Redpanda

[http://localhost:8080](http://localhost:8080)

---




## VidÃ©o de prÃ©sentation et de dÃ©monstration du pipeline
https://youtu.be/QhyixvDcppk




##  Structure du projet

```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ redpanda/
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ generator/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ tickets_generator.py
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pyspark_stream_tickets.py
â”œâ”€â”€ output/
â”‚   â””â”€â”€ aggregations/   # Sorties JSON du flux Spark
â””â”€â”€ README.md
```

---

##  Exemple de sortie

### AgrÃ©gations en console :

```
+------------+----------+-----+
|type        |priority  |count|
+------------+----------+-----+
|support     |haute     | 124 |
|technique   |normale   |  87 |
|facturation |basse     |  42 |
|commercial  |critique  |  15 |
+------------+----------+-----+
```

### Fichier JSON gÃ©nÃ©rÃ© :

```json
{"type":"support","priority":"haute","count":124}
{"type":"technique","priority":"normale","count":87}
{"type":"facturation","priority":"basse","count":42}
{"type":"commercial","priority":"critique","count":15}
```

---

## RÃ©silience et gestion des erreurs

- TolÃ©rance aux messages JSON invalides
- Aucune interruption du flux en cas dâ€™erreur
- Checkpointing Spark activÃ© pour reprise automatique
- Reprise automatique du streaming aprÃ¨s redÃ©marrage du conteneur